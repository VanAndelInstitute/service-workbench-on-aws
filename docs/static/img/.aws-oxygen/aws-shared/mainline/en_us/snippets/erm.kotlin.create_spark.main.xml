<programlisting>
suspend fun createSparkCluster(
    jarVal: String?,
    myClass: String?,
    keysVal: String?,
    logUriVal: String?,
    nameVal: String?
): String? {

        val jarStepConfig = HadoopJarStepConfig {
            jar = jarVal
            mainClass = myClass
        }

        val app = Application {
            name = "Spark"
        }

        val enabledebugging = StepConfig {
            name = "Enable debugging"
            actionOnFailure = ActionOnFailure.fromValue("TERMINATE_JOB_FLOW")
            hadoopJarStep = jarStepConfig
        }

        val instancesConfig = JobFlowInstancesConfig {
            ec2SubnetId = "subnet-206a9c58"
            ec2KeyName = keysVal
            instanceCount = 3
            keepJobFlowAliveWhenNoSteps = true
            masterInstanceType = "m4.large"
            slaveInstanceType = "m4.large"
        }

        val request = RunJobFlowRequest {
            name = nameVal
            releaseLabel = "emr-5.20.0"
            steps = listOf(enabledebugging)
            applications = listOf(app)
            logUri = logUriVal
            serviceRole = "EMR_DefaultRole"
            jobFlowRole = "EMR_EC2_DefaultRole"
            instances = instancesConfig
        }

        EmrClient { region = "us-west-2" }.use { emrClient ->
            val response = emrClient.runJobFlow(request)
            return response.jobFlowId
        }
    }

</programlisting>