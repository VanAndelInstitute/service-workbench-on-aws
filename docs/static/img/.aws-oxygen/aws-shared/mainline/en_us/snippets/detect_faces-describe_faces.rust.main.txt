async fn describe_faces(
    verbose: bool,
    client: &aws_sdk_rekognition::Client,
    image: aws_sdk_rekognition::model::Image,
) -> Result<(), aws_sdk_rekognition::Error> {
    let resp = client
        .detect_faces()
        .image(image)
        .attributes(aws_sdk_rekognition::model::Attribute::All)
        .send()
        .await?;

    // Create vector of persons
    let mut persons: Vec<Person> = vec![];

    for detail in resp.face_details.unwrap_or_default() {
        if verbose {
            println!("{:?}", detail);
            println!();
        }

        let age = detail.age_range.unwrap();
        let mut range: String = age.low.unwrap_or_default().to_string().to_owned();
        range.push('-');
        range.push_str(&age.high.unwrap_or_default().to_string());

        // Get the emotion with the greatest value
        let mut e: String = String::from("");

        let mut confidence = 0.0;

        for emotion in detail.emotions.unwrap_or_default() {
            let c = emotion.confidence.unwrap_or_default();
            if c > confidence {
                confidence = c;
                e = String::from(emotion.r#type.unwrap().as_ref());
            }
        }

        let p = Person {
            from_left: detail.bounding_box.unwrap().left.unwrap_or_default(),
            age_range: range,
            gender: String::from(detail.gender.unwrap().value.unwrap().as_ref()),
            emotion: e,
        };

        persons.push(p);
    }

    // Sort vector by from_left value.
    persons.sort_by(|a, b| a.from_left.partial_cmp(&b.from_left).unwrap());

    if !verbose {
        println!("Face details (from left):");
        println!();

        for p in persons {
            println!("From left: {}", p.from_left);
            println!("Age range: {}", p.age_range);
            println!("Gender:    {}", p.gender);
            println!("Emotion:   {}", p.emotion);
            println!();
        }
    }

    Ok(())
}
